---
title: AI Integration
description: Integrate artificial intelligence capabilities into your Discraft Discord bot.
---

# AI Integration

Integrating Artificial Intelligence (AI) into your Discraft Discord bot can unlock powerful and engaging functionalities, from generating dynamic responses and summarizing text to image creation and complex conversational agents. This guide will walk you through the process of connecting your Discraft bot with AI services, focusing on the Vercel AI SDK and OpenAI.

## Why Integrate AI?

AI can significantly enhance your bot's capabilities, enabling features such as:
- **Intelligent Chatbots:** Respond to user queries with context-aware and natural language understanding.
- **Content Generation:** Generate text (e.g., stories, summaries, code), images, or even audio based on prompts.
- **Moderation:** Automate content filtering and moderation tasks.
- **Data Analysis:** Process and respond to complex data or sentiment analysis.

## Setting Up AI Integration

### 1. Choose an AI Provider

Popular choices include:
- **OpenAI:** Provides powerful models like GPT-3.5, GPT-4 for text, DALL-E for images, and Whisper for speech-to-text.
- **Vercel AI SDK:** A universal JavaScript SDK for building AI applications with support for various models (OpenAI, Anthropic, Hugging Face, etc.). It simplifies streaming responses and handling different providers.

For this guide, we'll primarily use the Vercel AI SDK, which works seamlessly with OpenAI and other providers.

### 2. Install Dependencies

You'll need to install the `openai` and `ai` packages:

```bash
npm install openai ai
# or
yarn add openai ai
# or
pnpm add openai ai
```

### 3. Configure Environment Variables

AI services typically require API keys for authentication. Store these securely in your `.env` file:

```
DISCORD_TOKEN=YOUR_DISCORD_BOT_TOKEN
OPENAI_API_KEY=YOUR_OPENAI_API_KEY
```

Remember to add `.env` to your `.gitignore` to prevent committing sensitive information.

### 4. Initialize the AI Client

In your bot's entry point or a dedicated utility file (e.g., `utils/aiClient.js`), initialize your AI provider.

```javascript
// utils/openaiClient.js
const OpenAI = require('openai');

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

module.exports = { openai };
```

## Creating an AI Command

Let's create a simple command that takes a user's prompt and generates a response using a large language model.

```javascript
discraft-js/apps/web/docs/content/docs/templates/vercel-ai.mdx#L104-148
// commands/ai.js
const { SlashCommandBuilder } = require('discord.js');
const { OpenAIStream, StreamingTextResponse } = require('ai');
const OpenAI = require('openai'); // Already installed via 'ai' or separately

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const command = {
  data: new SlashCommandBuilder()
    .setName('ai')
    .setDescription('Interact with a large language model.')
    .addStringOption(option =>
      option.setName('prompt')
        .setDescription('The prompt for the AI.')
        .setRequired(true)
    ),
  execute: async (interaction) => {
    const prompt = interaction.options.getString('prompt');

    try {
      // Defer the reply if the AI response might take time
      await interaction.deferReply(); 

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo', // Or 'gpt-4' or other models
        messages: [{ role: 'user', content: prompt }],
        stream: true, // Enable streaming for potentially long responses
      });

      // Process the stream and build the response
      let aiResponse = '';
      for await (const chunk of OpenAIStream(response)) {
        aiResponse += chunk; // OpenAIStream utility handles JSON parsing etc.
        // For Discord, you might send partial updates or edit the initial deferred reply
      }
      
      // Discord messages have a character limit (2000). Truncate if necessary.
      const maxLen = 1900; 
      const finalResponse = aiResponse.length > maxLen 
        ? `${aiResponse.substring(0, maxLen)}... (truncated)` 
        : aiResponse;

      await interaction.editReply(`**Prompt:** "${prompt}"\n\n**AI Response:**\n${finalResponse}`);

    } catch (error) {
      console.error('AI Error:', error);
      // Reply to the user that an error occurred, visible only to them
      await interaction.editReply({ 
        content: 'There was an error while trying to get an AI response. Please try again later.', 
        ephemeral: true 
      });
    }
  },
};

module.exports = command;
```

**Explanation:**
- `SlashCommandBuilder`: Defines the command name, description, and a required `prompt` option.
- `interaction.deferReply()`: It's good practice to defer the reply for commands that might take longer than 3 seconds to respond, to prevent a "This interaction failed" error.
- `openai.chat.completions.create`: This is the core call to the OpenAI API.
    - `model`: Specifies the AI model to use (e.g., `gpt-3.5-turbo`, `gpt-4`).
    - `messages`: An array of message objects, where `role` is `user`, `system`, or `assistant`.
    - `stream: true`: Crucial for getting responses chunk by chunk, which is beneficial for long responses and better user experience.
- `OpenAIStream(response)`: The Vercel AI SDK provides this helper to easily consume the streamed response from OpenAI.
- `interaction.editReply()`: After deferring, you must use `editReply` to send the actual response.

## Advanced AI Use Cases

### Image Generation (DALL-E)

You can integrate image generation directly into your bot:

```javascript
// commands/generateImage.js
const { SlashCommandBuilder } = require('discord.js');
const { openai } = require('../utils/openaiClient'); // Assume you have this client initialized

const command = {
  data: new SlashCommandBuilder()
    .setName('generate-image')
    .setDescription('Generates an image using AI.')
    .addStringOption(option =>
      option.setName('description')
        .setDescription('A description of the image to generate.')
        .setRequired(true)
    ),
  execute: async (interaction) => {
    const description = interaction.options.getString('description');
    await interaction.deferReply();

    try {
      const image = await openai.images.generate({
        prompt: description,
        n: 1, // Number of images to generate
        size: '1024x1024', // Image size
      });

      const imageUrl = image.data[0].url;
      await interaction.editReply({ 
        content: `Here is your image:\n${imageUrl}`,
        files: [imageUrl] // Optionally send as an attachment
      });

    } catch (error) {
      console.error('Image generation error:', error);
      await interaction.editReply({ 
        content: 'Failed to generate image. Please try again later.', 
        ephemeral: true 
      });
    }
  },
};

module.exports = command;
```

### Conversational AI

For a more persistent conversational experience, you might store conversation history (e.g., in a database or a simple in-memory map for testing) and pass it to the AI model with each new prompt.

```javascript
// Example for managing conversation history (simplified)
const conversations = new Map(); // Map<userId, [{ role: 'user'|'assistant', content: string }]>

// In your messageCreate event or AI command execute:
// ... (inside execute/event handler)
const userId = interaction.user.id;
if (!conversations.has(userId)) {
  conversations.set(userId, []);
}
const userMessages = conversations.get(userId);

userMessages.push({ role: 'user', content: prompt });

const chatCompletion = await openai.chat.completions.create({
  model: 'gpt-3.5-turbo',
  messages: userMessages, // Send the entire conversation history
});

const aiMessage = chatCompletion.choices[0].message.content;
userMessages.push({ role: 'assistant', content: aiMessage });

await interaction.editReply(aiMessage);
// ...
```

## Best Practices for AI Integration

1.  **API Key Security:** Never hardcode API keys. Always use environment variables (`process.env.YOUR_API_KEY`).
2.  **Error Handling:** Implement robust `try-catch` blocks to gracefully handle API errors, rate limits, or network issues. Inform the user if something goes wrong.
3.  **Rate Limiting:** Be mindful of API rate limits imposed by AI providers. For complex bots, consider implementing your own rate-limiting mechanisms or back-off strategies.
4.  **Asynchronous Operations:** AI calls are network requests and should always be `await`ed. Use `interaction.deferReply()` for commands that might take time.
5.  **Message Length:** Discord has character limits for messages (2000 characters). Truncate or paginate long AI responses.
6.  **Cost Management:** Be aware of the costs associated with AI API usage, especially for higher-tier models or extensive usage.
7.  **User Experience:** Provide clear feedback to users (e.g., "AI is thinking...", "Generating image...") and handle errors gracefully.
8.  **Model Selection:** Choose the appropriate AI model for your task. GPT-3.5 is good for general chat, while GPT-4 offers more advanced reasoning. Specialized models exist for specific tasks.

## Next Steps

-   [Vercel AI SDK Documentation](https://sdk.vercel.ai/docs): Explore the official documentation for advanced usage.
-   [OpenAI API Documentation](https://platform.openai.com/docs/api-reference): Learn more about OpenAI's various models and endpoints.
-   [Core Concepts: Command System](/docs/core-concepts/command-system): Reinforce your understanding of how commands work in Discraft.
-   [Advanced Topics: Custom Events](/docs/advanced-topics/custom-events): Consider how events might trigger AI interactions (e.g., AI analysis of every message).